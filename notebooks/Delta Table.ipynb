{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "from deltalake import DeltaTable\n",
    "\n",
    "PATH = Path(\"./my-test-timelake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_data(\n",
    "    num_rows: int = 100_000_0,\n",
    "    asset_ids: list[str] = [\"AAPL\", \"MSFT\", \"GOOG\", \"TSLA\"],\n",
    "    start_date: datetime = datetime(2023, 1, 1),\n",
    ") -> pl.DataFrame:\n",
    "    assert num_rows >= len(asset_ids), (\n",
    "        \"num_rows must be at least equal to the number of asset_ids\"\n",
    "    )\n",
    "    rows_per_asset = num_rows // len(asset_ids)\n",
    "    all_data = []\n",
    "\n",
    "    for asset_id in asset_ids:\n",
    "        dates = [start_date + timedelta(hours=i) for i in range(rows_per_asset)]\n",
    "        prices = [\n",
    "            round(100 + i * 0.05 + (i % 24) * 0.3 + random.uniform(-1, 1), 2)\n",
    "            for i in range(rows_per_asset)\n",
    "        ]\n",
    "        volumes = [\n",
    "            int(1000 + i * 2 + (i % 10) * 50 + random.randint(-20, 20))\n",
    "            for i in range(rows_per_asset)\n",
    "        ]\n",
    "        asset_col = [asset_id] * rows_per_asset\n",
    "\n",
    "        all_data.append(\n",
    "            pl.DataFrame(\n",
    "                {\n",
    "                    \"date\": dates,\n",
    "                    \"asset_id\": asset_col,\n",
    "                    \"price\": prices,\n",
    "                    \"volume\": volumes,\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return pl.concat(all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date</th><th>asset_id</th><th>price</th><th>volume</th></tr><tr><td>datetime[μs]</td><td>str</td><td>f64</td><td>i64</td></tr></thead><tbody><tr><td>2023-01-01 00:00:00</td><td>&quot;AAPL&quot;</td><td>99.99</td><td>990</td></tr><tr><td>2023-01-01 01:00:00</td><td>&quot;AAPL&quot;</td><td>99.81</td><td>1054</td></tr><tr><td>2023-01-01 02:00:00</td><td>&quot;AAPL&quot;</td><td>99.78</td><td>1122</td></tr><tr><td>2023-01-01 03:00:00</td><td>&quot;AAPL&quot;</td><td>101.46</td><td>1149</td></tr><tr><td>2023-01-01 04:00:00</td><td>&quot;AAPL&quot;</td><td>100.84</td><td>1195</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌─────────────────────┬──────────┬────────┬────────┐\n",
       "│ date                ┆ asset_id ┆ price  ┆ volume │\n",
       "│ ---                 ┆ ---      ┆ ---    ┆ ---    │\n",
       "│ datetime[μs]        ┆ str      ┆ f64    ┆ i64    │\n",
       "╞═════════════════════╪══════════╪════════╪════════╡\n",
       "│ 2023-01-01 00:00:00 ┆ AAPL     ┆ 99.99  ┆ 990    │\n",
       "│ 2023-01-01 01:00:00 ┆ AAPL     ┆ 99.81  ┆ 1054   │\n",
       "│ 2023-01-01 02:00:00 ┆ AAPL     ┆ 99.78  ┆ 1122   │\n",
       "│ 2023-01-01 03:00:00 ┆ AAPL     ┆ 101.46 ┆ 1149   │\n",
       "│ 2023-01-01 04:00:00 ┆ AAPL     ┆ 100.84 ┆ 1195   │\n",
       "└─────────────────────┴──────────┴────────┴────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_sample_data()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We test a little bit the polars code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write_delta(\n",
    "    target=PATH,\n",
    "    mode=\"overwrite\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DeltaTable(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeltaTable()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can open it in data wrangler!!\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Schema([Field(date, PrimitiveType(\"timestamp_ntz\"), nullable=True), Field(asset_id, PrimitiveType(\"string\"), nullable=True), Field(price, PrimitiveType(\"double\"), nullable=True), Field(volume, PrimitiveType(\"long\"), nullable=True)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.partitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read completed in 0.009 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pl.read_delta(dt)\n",
    "end = time.time()\n",
    "print(f\"Read completed in {end - start:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numFilesAdded': 1,\n",
       " 'numFilesRemoved': 4,\n",
       " 'filesAdded': '{\"avg\":9196174.0,\"max\":9196174,\"min\":9196174,\"totalFiles\":1,\"totalSize\":9196174}',\n",
       " 'filesRemoved': '{\"avg\":4474110.5,\"max\":4474666,\"min\":4473499,\"totalFiles\":4,\"totalSize\":17896442}',\n",
       " 'partitionsOptimized': 1,\n",
       " 'numBatches': 980,\n",
       " 'totalConsideredFiles': 4,\n",
       " 'totalFilesSkipped': 0,\n",
       " 'preserveInsertionOrder': True}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.optimize.compact()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read completed in 0.067 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pl.read_delta(dt)\n",
    "end = time.time()\n",
    "print(f\"Read completed in {end - start:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read completed in 0.012 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pl.read_delta(dt, columns=\"date\")\n",
    "end = time.time()\n",
    "print(f\"Read completed in {end - start:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read completed in 0.058 seconds\n"
     ]
    }
   ],
   "source": [
    "# When we don't push down the filtering\n",
    "start = time.time()\n",
    "df = pl.read_delta(dt)\n",
    "df.filter(df[\"date\"].cast(pl.Date) == pl.lit(\"2023-01-01\").cast(pl.Date))\n",
    "end = time.time()\n",
    "print(f\"Read completed in {end - start:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read completed in 0.022 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusgarsdal/Personal/timelake/.venv/lib/python3.10/site-packages/polars/io/delta.py:454: RuntimeWarning: When supplying a DeltaTable directly, `version`, `storage_options`, and `delta_table_options` are ignored.\n",
      "                To silence this warning, don't supply those parameters.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# This does not seem to work, perhaps because we have no partitioning\n",
    "start = time.time()\n",
    "pl.read_delta(\n",
    "    dt,\n",
    "    delta_table_options={\n",
    "        \"predicate\": [\n",
    "            pl.col(\"date\").cast(pl.Date) == pl.lit(\"2023-01-01\").cast(pl.Date)\n",
    "        ]\n",
    "    },\n",
    ")\n",
    "end = time.time()\n",
    "print(f\"Read completed in {end - start:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We try a new table partitioned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PARTITIONED = Path(\"./my-test-timelake-partitioned\")\n",
    "df.write_delta(\n",
    "    target=PATH_PARTITIONED,\n",
    "    mode=\"overwrite\",\n",
    "    delta_write_options={\n",
    "        \"partition_by\": [\"asset_id\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "dt_partitioned = DeltaTable(PATH_PARTITIONED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read completed in 0.009 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df = pl.read_delta(\n",
    "    dt_partitioned,\n",
    ")\n",
    "end = time.time()\n",
    "print(f\"Read completed in {end - start:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read completed in 0.061 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pl.from_arrow(dt_partitioned.to_pyarrow_table(partitions=[(\"asset_id\", \"=\", \"AAPL\")]))\n",
    "end = time.time()\n",
    "print(f\"Read completed in {end - start:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read completed in 0.010 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df = pl.read_delta(\n",
    "    dt_partitioned,\n",
    "    pyarrow_options={\"partitions\": [(\"asset_id\", \"=\", \"AAPL\")]},\n",
    "    use_pyarrow=True,\n",
    ")\n",
    "end = time.time()\n",
    "print(f\"Read completed in {end - start:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Schema([Field(date, PrimitiveType(\"timestamp_ntz\"), nullable=True), Field(asset_id, PrimitiveType(\"string\"), nullable=True), Field(price, PrimitiveType(\"double\"), nullable=True), Field(volume, PrimitiveType(\"long\"), nullable=True)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.metadata().partition_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'asset_id': 'GOOG'},\n",
       " {'asset_id': 'MSFT'},\n",
       " {'asset_id': 'TSLA'},\n",
       " {'asset_id': 'AAPL'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_partitioned.partitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We test upserts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "y",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "20fdd13a-7ba3-4878-9f99-c4e51ba655cb",
       "rows": [
        [
         "0",
         "1",
         "4"
        ],
        [
         "1",
         "2",
         "5"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x  y\n",
       "0  1  4\n",
       "1  2  5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "from deltalake import DeltaTable, write_deltalake\n",
    "\n",
    "data = pa.table({\"x\": [1, 2, 3], \"y\": [4, 5, 6]})\n",
    "write_deltalake(\"tmp\", data)\n",
    "dt = DeltaTable(\"tmp\")\n",
    "new_data = pa.table({\"x\": [2, 3], \"deleted\": [False, True]})\n",
    "\n",
    "(\n",
    "    dt.merge(\n",
    "        source=new_data,\n",
    "        predicate=\"target.x = source.x\",\n",
    "        source_alias=\"source\",\n",
    "        target_alias=\"target\",\n",
    "    )\n",
    "    .when_matched_delete(predicate=\"source.deleted = true\")\n",
    "    .execute()\n",
    ")\n",
    "dt.to_pandas().sort_values(\"x\", ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
